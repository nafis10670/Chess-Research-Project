{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import chess\n",
    "from stockfish import Stockfish\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function to calculate the size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Completed\n"
     ]
    }
   ],
   "source": [
    "# ################ monkey patch for quanto\n",
    "def named_module_tensors(module, recurse=False):\n",
    "    for named_parameter in module.named_parameters(recurse=recurse):\n",
    "      name, val = named_parameter\n",
    "      flag = True\n",
    "      if hasattr(val,\"_data\") or hasattr(val,\"_scale\"):\n",
    "        if hasattr(val,\"_data\"):\n",
    "          yield name + \"._data\", val._data\n",
    "        if hasattr(val,\"_scale\"):\n",
    "          yield name + \"._scale\", val._scale\n",
    "      else:\n",
    "        yield named_parameter\n",
    "\n",
    "    for named_buffer in module.named_buffers(recurse=recurse):\n",
    "      yield named_buffer\n",
    "\n",
    "def dtype_byte_size(dtype):\n",
    "    \"\"\"\n",
    "    Returns the size (in bytes) occupied by one parameter of type `dtype`.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    if dtype == torch.bool:\n",
    "        return 1 / 8\n",
    "    bit_search = re.search(r\"[^\\d](\\d+)$\", str(dtype))\n",
    "    if bit_search is None:\n",
    "        raise ValueError(f\"`dtype` is not a valid dtype: {dtype}.\")\n",
    "    bit_size = int(bit_search.groups()[0])\n",
    "    return bit_size // 8\n",
    "\n",
    "def compute_module_sizes(model):\n",
    "    \"\"\"\n",
    "    Compute the size of each submodule of a given model.\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    module_sizes = defaultdict(int)\n",
    "    for name, tensor in named_module_tensors(model, recurse=True):\n",
    "      size = tensor.numel() * dtype_byte_size(tensor.dtype)\n",
    "      name_parts = name.split(\".\")\n",
    "      for idx in range(len(name_parts) + 1):\n",
    "        module_sizes[\".\".join(name_parts[:idx])] += size\n",
    "\n",
    "    return module_sizes\n",
    "\n",
    "print(\"Execution Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = chess.Board()\n",
    "\n",
    "stockfish = Stockfish()\n",
    "stockfish.set_depth(20)\n",
    "stockfish.set_skill_level(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:30<00:00,  3.80s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"  # Replace with the actual model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", low_cpu_mem_usage=True)\n",
    "# model = model.to('mps')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    config=bnb_config,\n",
    "    low_cpu_mem_usage=True,\n",
    "    offload_folder=\"./offload\",  # Folder to offload parameters if needed\n",
    "    torch_dtype=torch.float16,  # Use half-precision (float16) to save memory\n",
    "    use_safetensors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.0.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.1.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.2.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.3.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.4.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.5.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.6.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.7.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.8.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.9.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.10.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.11.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.12.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.13.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.14.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.15.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.16.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.17.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.18.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.19.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.20.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.21.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.22.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.23.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.24.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.25.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.26.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.27.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.28.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.28.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.29.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.29.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.30.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.30.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.31.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.31.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.32.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.32.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.33.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.33.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.34.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.34.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.35.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.35.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.36.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.36.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.37.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.37.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.38.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.38.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.39.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.39.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.40.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.40.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.41.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.41.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.42.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.42.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.43.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.43.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.44.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.44.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.45.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.45.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.46.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.46.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.47.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.47.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.48.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.48.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.49.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.49.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.50.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.50.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.51.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.51.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.52.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.52.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.53.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.53.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.54.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.54.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.55.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.55.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.56.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.56.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.57.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.57.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.58.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.58.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.59.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.59.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.60.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.60.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.61.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.61.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.62.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.62.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.63.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.63.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.norm.weight is loaded in torch.float16\n",
      "lm_head.weight is loaded in torch.float16\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def print_param_dtype(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name} is loaded in {param.dtype}\")\n",
    "\n",
    "print(print_param_dtype(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.0.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.0.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.0.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.0.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.1.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.1.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.1.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.1.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.2.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.2.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.2.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.2.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.3.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.3.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.3.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.3.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.4.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.4.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.4.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.4.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.5.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.5.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.5.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.5.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.6.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.6.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.6.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.6.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.7.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.7.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.7.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.7.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.8.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.8.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.8.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.8.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.9.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.9.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.9.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.9.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.10.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.10.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.10.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.10.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.11.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.11.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.11.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.11.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.12.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.12.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.12.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.12.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.13.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.13.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.13.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.13.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.14.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.14.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.14.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.14.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.15.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.15.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.15.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.15.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.16.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.16.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.16.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.16.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.17.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.17.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.17.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.17.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.18.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.18.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.18.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.18.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.19.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.19.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.19.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.19.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.20.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.20.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.20.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.20.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.21.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.21.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.21.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.21.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.22.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.22.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.22.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.22.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.23.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.23.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.23.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.23.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.24.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.24.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.24.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.24.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.25.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.25.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.25.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.25.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.26.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.26.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.26.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.26.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.27.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.27.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.27.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.27.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.28.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.28.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.28.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.28.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.28.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.29.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.29.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.29.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.29.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.29.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.30.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.30.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.30.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.30.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.30.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.31.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.31.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.31.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.31.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.31.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.32.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.32.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.32.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.32.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.32.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.33.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.33.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.33.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.33.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.33.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.34.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.34.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.34.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.34.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.34.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.35.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.35.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.35.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.35.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.35.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.36.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.36.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.36.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.36.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.36.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.37.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.37.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.37.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.37.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.37.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.38.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.38.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.38.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.38.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.38.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.39.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.39.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.39.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.39.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.39.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.40.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.40.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.40.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.40.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.40.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.41.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.41.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.41.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.41.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.41.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.42.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.42.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.42.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.42.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.42.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.43.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.43.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.43.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.43.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.43.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.44.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.44.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.44.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.44.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.44.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.45.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.45.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.45.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.45.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.45.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.46.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.46.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.46.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.46.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.46.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.47.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.47.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.47.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.47.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.47.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.48.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.48.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.48.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.48.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.48.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.49.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.49.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.49.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.49.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.49.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.50.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.50.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.50.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.50.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.50.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.51.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.51.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.51.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.51.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.51.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.52.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.52.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.52.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.52.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.52.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.53.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.53.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.53.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.53.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.53.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.54.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.54.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.54.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.54.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.54.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.55.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.55.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.55.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.55.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.55.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.56.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.56.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.56.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.56.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.56.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.57.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.57.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.57.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.57.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.57.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.58.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.58.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.58.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.58.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.58.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.59.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.59.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.59.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.59.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.59.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.60.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.60.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.60.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.60.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.60.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.61.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.61.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.61.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.61.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.61.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.62.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.62.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.62.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.62.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.62.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.q_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.q_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.k_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.k_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.v_proj.weight is loaded in torch.float16\n",
      "model.layers.63.self_attn.v_proj.bias is loaded in torch.float16\n",
      "model.layers.63.self_attn.o_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.gate_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.up_proj.weight is loaded in torch.float16\n",
      "model.layers.63.mlp.down_proj.weight is loaded in torch.float16\n",
      "model.layers.63.input_layernorm.weight is loaded in torch.float16\n",
      "model.layers.63.post_attention_layernorm.weight is loaded in torch.float16\n",
      "model.norm.weight is loaded in torch.float16\n",
      "lm_head.weight is loaded in torch.float16\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model2 = model2.half()\n",
    "print(print_param_dtype(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens': 'mps', 'model.layers.0': 'mps', 'model.layers.1': 'mps', 'model.layers.2': 'mps', 'model.layers.3': 'mps', 'model.layers.4': 'mps', 'model.layers.5': 'mps', 'model.layers.6': 'mps', 'model.layers.7': 'mps', 'model.layers.8': 'mps', 'model.layers.9': 'mps', 'model.layers.10': 'mps', 'model.layers.11': 'mps', 'model.layers.12': 'mps', 'model.layers.13': 'mps', 'model.layers.14': 'mps', 'model.layers.15': 'disk', 'model.layers.16': 'disk', 'model.layers.17': 'disk', 'model.layers.18': 'disk', 'model.layers.19': 'disk', 'model.layers.20': 'disk', 'model.layers.21': 'disk', 'model.layers.22': 'disk', 'model.layers.23': 'disk', 'model.layers.24': 'disk', 'model.layers.25': 'disk', 'model.layers.26': 'disk', 'model.layers.27': 'disk', 'model.layers.28': 'disk', 'model.layers.29': 'disk', 'model.layers.30': 'disk', 'model.layers.31': 'disk', 'model.layers.32': 'disk', 'model.layers.33': 'disk', 'model.layers.34': 'disk', 'model.layers.35': 'disk', 'model.layers.36': 'disk', 'model.layers.37': 'disk', 'model.layers.38': 'disk', 'model.layers.39': 'disk', 'model.layers.40': 'disk', 'model.layers.41': 'disk', 'model.layers.42': 'disk', 'model.layers.43': 'disk', 'model.layers.44': 'disk', 'model.layers.45': 'disk', 'model.layers.46': 'disk', 'model.layers.47': 'disk', 'model.layers.48': 'disk', 'model.layers.49': 'disk', 'model.layers.50': 'disk', 'model.layers.51': 'disk', 'model.layers.52': 'disk', 'model.layers.53': 'disk', 'model.layers.54': 'disk', 'model.layers.55': 'disk', 'model.layers.56': 'disk', 'model.layers.57': 'disk', 'model.layers.58': 'disk', 'model.layers.59': 'disk', 'model.layers.60': 'disk', 'model.layers.61': 'disk', 'model.layers.62': 'disk', 'model.layers.63': 'disk', 'model.norm': 'disk', 'model.rotary_emb': 'disk', 'lm_head': 'disk'}\n"
     ]
    }
   ],
   "source": [
    "print(model.hf_device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Board:\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Board:\")\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e4\n",
      "\n",
      "I'm not sure what to\n",
      "Deepseek generated an invalid move.\n"
     ]
    }
   ],
   "source": [
    "while not board.is_game_over():\n",
    "    prompt = f\"Chess Position: {board.fen()}\\nBest Move:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_new_tokens=10)\n",
    "    move_str = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Best Move:\")[-1].strip()\n",
    "    print(move_str)\n",
    "    \n",
    "    try:\n",
    "        move = chess.Move.from_uci(move_str)\n",
    "        if move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            print(f\"Deepseek Move: {move}\")\n",
    "        else:\n",
    "            print(\"Deepseek generated an invalid move.\")\n",
    "            break\n",
    "    except:\n",
    "        print(\"Deepseek generated an invalid move.\")\n",
    "        break\n",
    "    \n",
    "    if board.is_game_over():\n",
    "        break\n",
    "    \n",
    "    stockfish.set_fen_position(board.fen())\n",
    "    stockfish_move = stockfish.get_best_move()\n",
    "    board.push(chess.Move.from_uci(stockfish_move))\n",
    "    print(f\"Stockfish Move: {stockfish_move}\")\n",
    "    \n",
    "    display(SVG(chess.svg.board(board=board)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You can't move a model that has some modules offloaded to cpu or disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m<|system|>\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mYou are a chess engine. Analyze the current position and provide the best move.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mThe current position in FEN is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfen_position\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m<|assistant|>\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ensure using MPS\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# Move model to MPS\u001b[39;00m\n\u001b[1;32m     15\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move input_ids to MPS\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Generate move with Deepseek\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/big_modeling.py:458\u001b[0m, in \u001b[0;36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You can't move a model that has some modules offloaded to cpu or disk."
     ]
    }
   ],
   "source": [
    "while not board.is_game_over():\n",
    "    # Deepseek's turn\n",
    "    fen_position = board.fen()\n",
    "    \n",
    "    # Create prompt for Deepseek\n",
    "    prompt = f\"\"\"<|system|>\n",
    "    You are a chess engine. Analyze the current position and provide the best move.\n",
    "    The current position in FEN is: {fen_position}\n",
    "    <|user|>\n",
    "    What is the best move in UCI format?\n",
    "    <|assistant|>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate move with Deepseek\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "    deepseek_move = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # print(deepseek_move)\n",
    "    \n",
    "    # Extract UCI move from response\n",
    "    legal_moves = [move.uci() for move in board.legal_moves]\n",
    "    selected_move = None\n",
    "    for move in legal_moves:\n",
    "        if move in deepseek_move:\n",
    "            selected_move = move\n",
    "            break\n",
    "    \n",
    "    # Fallback to first legal move if no valid move found\n",
    "    if not selected_move:\n",
    "        selected_move = legal_moves[0]\n",
    "    \n",
    "    # Make the move on the board\n",
    "    move_obj = chess.Move.from_uci(selected_move)\n",
    "    board.push(move_obj)\n",
    "    print(f\"Deepseek plays: {selected_move}\")\n",
    "    print(board)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if board.is_game_over():\n",
    "        break\n",
    "    \n",
    "    # Stockfish's turn\n",
    "    stockfish.set_fen_position(board.fen())\n",
    "    best_move = stockfish.get_best_move_time(100)\n",
    "    move_obj = chess.Move.from_uci(best_move)\n",
    "    board.push(move_obj)\n",
    "    print(f\"Stockfish plays: {best_move}\")\n",
    "    print(board)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Over.\n",
      "Result: 0-1\n"
     ]
    }
   ],
   "source": [
    "print(\"Game Over.\")\n",
    "print(\"Result:\", board.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/generation/utils.py:2137: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# device = torch.device(\"mps\")  # Ensure using MPS\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# model.to(device)              # Move model to MPS\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# input_ids = input_ids.to(device)  # Move input_ids to MPS\u001b[39;00m\n\u001b[1;32m     29\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(p, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m deepseek_move \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(deepseek_move)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/generation/utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3260\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3261\u001b[0m     outputs,\n\u001b[1;32m   3262\u001b[0m     model_kwargs,\n\u001b[1;32m   3263\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3264\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:816\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 816\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:574\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    563\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    564\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    571\u001b[0m         position_embeddings,\n\u001b[1;32m    572\u001b[0m     )\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 574\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:275\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    274\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 275\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    278\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:56\u001b[0m, in \u001b[0;36mQwen2MLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 56\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/hooks.py:336\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, _ \u001b[38;5;129;01min\u001b[39;00m named_module_tensors(\n\u001b[1;32m    330\u001b[0m     module,\n\u001b[1;32m    331\u001b[0m     include_buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffload_buffers,\n\u001b[1;32m    332\u001b[0m     recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_submodules,\n\u001b[1;32m    333\u001b[0m     remove_non_persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    334\u001b[0m ):\n\u001b[1;32m    335\u001b[0m     fp16_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_map\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/utils/offload.py:118\u001b[0m, in \u001b[0;36mPrefixedDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/env/lib/python3.12/site-packages/accelerate/utils/offload.py:171\u001b[0m, in \u001b[0;36mOffloadedWeightsLoader.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafetensors_file\u001b[39m\u001b[38;5;124m\"\u001b[39m], framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 171\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# if failed to get_tensor on the device, such as bf16 on mps, try to load it on CPU first\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(weight_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msafetensors_file\u001b[39m\u001b[38;5;124m\"\u001b[39m], framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "board2 = chess.Board()\n",
    "fen_position2 = board2.fen()\n",
    "\n",
    "p = \"Hello. I am Nafis.\"\n",
    "\n",
    "system_prompt = f\"\"\"<|system|>\n",
    "    You are a grandmaster-level chess engine specializing in aggressive play. \n",
    "\n",
    "    Guidelines:\n",
    "    1. Maximize your advantage or mitigate any risks.\n",
    "    2. Develop your pieces and strengthen your position.\n",
    "    3. Look for check opportunities.\n",
    "    4. Prioritize material gains when safe.\n",
    "    5. Look to control the center of the board.\n",
    "    \n",
    "    Respond ONLY with the UCI move in this format:\n",
    "    Best move: [your_move_here]\n",
    "    </s>\n",
    "    \"\"\"\n",
    "user_prompt = f\"<|user|>\\nThe current board position is: {board2.fen()}\\n What is the best move in this position?\\n<|assistant|>\\n\"\n",
    "    \n",
    "full_prompt = system_prompt + user_prompt\n",
    "\n",
    "# device = torch.device(\"mps\")  # Ensure using MPS\n",
    "# model.to(device)              # Move model to MPS\n",
    "# input_ids = input_ids.to(device)  # Move input_ids to MPS\n",
    "\n",
    "\n",
    "inputs = tokenizer(p, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "deepseek_move = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(deepseek_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
